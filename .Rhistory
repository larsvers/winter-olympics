View(decathlon)
?PCA
str(decathlon)
res.pca <- PCA(decathlon, quanti.sup = 11:12, quali.sup = 13)
str(res.pca)
print(res.pca)
res.pca$call
0.02439024*41
FactoMineR::plot(res.pca, habillage = 13)
plot.CA(res.pca, habillage = 13)
?plot.CA
?plot.PCA
plot.PCA(res.pca, habillage = 13)
barplot(res.pca$eig[,1], main = "Eigenvalues",
names.arg = paste("Dim", 1:nrow(res.pca$eig), sep = ""))
plot.PCA(res.pca, choix = "var", axes = c(3,4), lim.cos2.var = 0)
plot.PCA(res.pca, choix = "var", axes = c(9,10), lim.cos2.var = 0)
plot.PCA(res.pca, choix = "var", axes = c(8,9), lim.cos2.var = 0)
plot.PCA(res.pca, choix = "var", axes = c(4,5), lim.cos2.var = 0)
plot.PCA(res.pca, choix = "ind", axes = c(4,5), lim.cos2.var = 0)
plot.PCA(res.pca, choix = "var", axes = c(4,5), lim.cos2.var = 0)
plot.PCA(res.pca, choix = "var", axes = c(4,5), lim.cos2.var = 1)
plot.PCA(res.pca, choix = "var", axes = c(1,2), lim.cos2.var = 1)
plot.PCA(res.pca, choix = "var", axes = c(1,2), lim.cos2.var = .3)
plot.PCA(res.pca, choix = "var", axes = c(1,2), lim.cos2.var = .1)
plot.PCA(res.pca, choix = "var", axes = c(1,2), lim.cos2.var = .4)
plot.PCA(res.pca, choix = "var", axes = c(1,2), lim.cos2.var = .6)
plot.PCA(res.pca, choix = "var", axes = c(1,2), lim.cos2.var = .8)
plot.PCA(res.pca, choix = "var", axes = c(1,2), lim.cos2.var = .7)
plot.PCA(res.pca, habillage = 13)
plot.PCA(res.pca, choix = "var", axes = c(1,2), lim.cos2.var = 0)
plot.PCA(res.pca, habillage = 13)
View(df.pca.lemma.sparse)
FMR.pca <- PCA(df.pca.lemma.nonsparse)
FMR.pca <- PCA(df.pca.word.nonsparse)
FMR.pca <- PCA(df.pca.word.sparse)
FMR.pca <- PCA(df.pca.words.nonsparse)
FMR.pca <- PCA(df.pca.words.nonsparse, choix="var", lim.cos2.var = 0.5)
plot.PCA(FMR.pca, choix = "var", lim.cos2.var = .5)
plot.PCA(FMR.pca, choix = "var", lim.cos2.var = .3)
plot.PCA(FMR.pca, choix = "var", lim.cos2.var = .4)
plot.PCA(FMR.pca, choix = "var", lim.cos2.var = .5)
plot.PCA(FMR.pca, choix = "var", lim.cos2.var = .6)
barplot(FMR.pca$eig[,1], main = "Eigenvalues",
names.arg = paste("Dim", 1:nrow(res.pca$eig), sep = ""))
barplot(FMR.pca$eig[,1], main = "Eigenvalues",
names.arg = paste("Dim", 1:nrow(FMR.pca$eig), sep = ""))
plot.PCA(FMR.pca, choix = "var", axes = c(3,4), lim.cos2.var = .6)
plot.PCA(FMR.pca, choix = "var", axes = c(3,4), lim.cos2.var = 0)
plot.PCA(FMR.pca, choix = "var", axes = c(3,4), lim.cos2.var = 0.1)
plot.PCA(FMR.pca, choix = "var", axes = c(1,2), lim.cos2.var = 0.6)
plot.PCA(FMR.pca)
plot.PCA(FMR.pca, lim.cos2.var = 0)
plot.PCA(FMR.pca, choix = "var", axes = c(1,2), lim.cos2.var = 0)
print(FMR.pca)
FMR.pca$call
print(FMR.pca)
FMR.pca$call$row.w
str(corpus.words)
str(corpus.words[[1]])
str(tdm.words.sparse)
head(tdm.words.sparse)
tdm.words.sparse
inspect(tdm.words.sparse)
inspect(tdm.words.sparse[1:10,1:4])
inspect(tdm.words.sparse[1:10,1:10])
inspect(tdm.words.sparse[1:10,1:20])
inspect(tdm.words.sparse[1:20,1:20])
inspect(tdm.words.sparse[1:10,1:20])
tdm.test <- TermDocumentMatrix(corpus.words, control = list(weighting = weightTfIdf))
str(tdm.words.sparse)
inspect(tdm.words.sparse[1:10,1:20])
str(tdm.test)
str(tdm.words.sparse)
str(tdm.test)
inspect(tdm.words.sparse[1:10,1:20])
inspect(tdm.test[1:10,1:20])
df.tdm.test <- tdm.test %>% as.matrix() %>% as.data.frame()
df.pca.test <- df.tdm.test
pca.run.to.biplot(df.tdm.test)
blub <- PCA(df.tdm.test)
pca.show.var.explained(df.tdm.test)
tdm.words.sparse <- TermDocumentMatrix(corpus.words, control = list(weighting = weightTfIdf))
tdm.lemma.sparse <- TermDocumentMatrix(corpus.lemma, control = list(weighting = weightTfIdf))
inspect(tdm.words.sparse[1:10,1:4])
inspect(tdm.lemma.sparse[1:10,1:4])
length(tdm.words.sparse$dimnames$Terms) # check length of matrix
length(findFreqTerms(tdm.words.sparse,10)) # find frequent terms
length(findFreqTerms(tdm.words.sparse,100)) # find frequent terms
length(findFreqTerms(tdm.words.sparse,1000)) # find frequent terms
head(findFreqTerms(tdm.words.sparse,10000)) # find frequent terms
a <- tdm.words.sparse %>% as.matrix() %>% as.data.frame()
b <- rownames(a)
c <- apply(a,1,sum)
df.words <- data_frame(word=b,count=c)
which(b %in% "the")
(df.words <- data_frame(word=b,count=c))
(df.words %>% arrange(desc(word)))
(df.words %>% arrange(desc(count)))
(df.words %>% arrange(count))
a <- tdm.lemma.sparse %>% as.matrix() %>% as.data.frame()
b <- rownames(a)
c <- apply(a,1,sum)
df.lemmas <- data_frame(word=b,count=c)
df.lemmas %>% arrange(desc(count))
fun.sparsity.vis <- function(matrix) {
# create vector with
v <- numeric(0)
v <- append(v, removeSparseTerms(matrix, 0.01)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.1)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.2)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.3)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.4)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.5)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.6)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.7)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.8)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.9)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.99)$nrow)
df <- data_frame(max.sparsity=c(0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99),
n=v) # data to plot
print(df)
# plot minimum's by returned words > choose visually (maybe the elbow)
ggplot(df,aes(max.sparsity, n, label = n)) +
geom_line() +
geom_label() +
labs(x = "maximum allowed sparsity per term in %", y = "number of retained terms in matrix")
}
fun.sparsity.vis(tdm.words.sparse)
fun.sparsity.vis(tdm.lemma.sparse)
tdm.words.nonsparse <- removeSparseTerms(tdm.words.sparse, 0.9)
tdm.lemma.nonsparse <- removeSparseTerms(tdm.lemma.sparse, 0.9)
fun.sparsity.vis(tdm.words.nonsparse)
fun.sparsity.vis(tdm.lemma.nonsparse)
df.tdm.words.nonsparse <- tdm.words.nonsparse %>% as.matrix() %>% as.data.frame()
df.tdm.lemma.nonsparse <- tdm.lemma.nonsparse %>% as.matrix() %>% as.data.frame()
df.tdm.words.sparse <- tdm.words.sparse %>% as.matrix() %>% as.data.frame()
df.tdm.lemma.sparse <- tdm.lemma.sparse %>% as.matrix() %>% as.data.frame()
nrow(df.tdm.lemma.nonsparse)
nrow(df.tdm.lemma.sparse)
nrow(df.tdm.words.nonsparse)
nrow(df.tdm.words.sparse)
head(df.tdm.words.nonsparse)
head(df.tdm.words.sparse)
head(df.tdm.lemma.nonsparse)
head(df.tdm.lemma.sparse)
fun.check.word.frequency <- function(data, NoOfWordsToShow = 500) {
f.sum <- rowSums(data)
f.stdev <- apply(data,1,sd)
f.words <- names(f.sum)
df.wordfreq <- data_frame(word = f.words, freq = f.sum, st.dev = f.stdev) # create df
df.wordfreq <- arrange(df.wordfreq,desc(freq)) # sort by word frequency
df.wordfreq <- mutate(df.wordfreq, division = st.dev/freq*100) # add variable that shows st.dev in relation to frequency. Remove only values were this measure is high (we want to keep words with a high standard deviation in relation to their frequency as should retain a reasonable amount of discriminatory value for the text clustering)
print(df.wordfreq, n = 20) # print the first 20 words
data.name <- deparse(substitute(data)) # get data object name
# show the top 100 frequent words
print(ggplot(df.wordfreq[1:NoOfWordsToShow,], aes(c(1:NoOfWordsToShow), freq)) +
geom_point() +
labs(title = paste("word frequency of", data.name, "\n for the", NoOfWordsToShow, "top occuring words - before removal"),
x = paste("top", NoOfWordsToShow, "words"),
y = "word frequency"))
return(df.wordfreq)
}
fun.remove.very.frequent.terms <- function(tdmatrix, maxNumOfWords = 10000) {
# create dataframe of words to keep
df.wordfreq <- df.wordfreq %>% dplyr::filter(freq < maxNumOfWords | (freq > maxNumOfWords & division > 4 )) # remove all words used more often than 'maxNumOfWords' times OR has a high standard dev.
df.wordfreq <- df.wordfreq %>% dplyr::filter(word != "and") # remove "and"
print(df.wordfreq, n = 20) # print frequent terms df with removed terms
data.name <- deparse(substitute(tdmatrix)) # get data name as character
# show plot
print(ggplot(df.wordfreq[1:100,], aes(c(1:100), freq)) +
geom_point() +
labs(title = paste("word frequency of", data.name, "\n for the 100 top occuring words - after removal"),
x = "top 100 words",
y = "word frequency"))
# create matrix with words to keep
vec.keep <- as.vector(unlist(df.wordfreq[,1]))
vec.keep <- sort(vec.keep)
r <- nrow(tdmatrix)
print(paste("rows of original tdm: ", r))
tdmatrix <- tdmatrix[vec.keep,]
print(paste("rows of new tdm: ", nrow(tdmatrix)))
print(paste("number of terms removed: ", r - nrow(tdmatrix)))
return(tdmatrix)
}
df.wordfreq <- fun.check.word.frequency(df.tdm.words.nonsparse) # look at the sorted word frequency
df.wordfreq <- fun.check.word.frequency(df.tdm.words.sparse) # look at the sorted word frequency
df.wordfreq <- fun.check.word.frequency(df.tdm.lemma.nonsparse) # look at the sorted word frequency
df.wordfreq <- fun.check.word.frequency(df.tdm.lemma.sparse) # look at the sorted word frequency
df.pca.words.nonsparse <- df.tdm.words.nonsparse
df.pca.words.sparse <- df.tdm.words.sparse
df.pca.lemma.nonsparse <- df.tdm.lemma.nonsparse
df.pca.lemma.sparse <- df.tdm.lemma.sparse
colnames(df.pca.words.nonsparse) <- text.names
colnames(df.pca.words.sparse) <- text.names
colnames(df.pca.lemma.nonsparse) <- text.names
colnames(df.pca.lemma.sparse) <- text.names
head(df.pca.words.nonsparse)
summary(df.pca.words.nonsparse)
View(df.pca.lemma.sparse)
pca.run.to.biplot <- function(data){
# run pca (w. standardsed data - ie. center and scale)
pca <- prcomp(data, scale. = T)
# diagnostics
print(pca$center) # the means used for centering
print(pca$scale) # the standard dev's used for scaling
print(pca$rotation) # the principal components (called the rotation matrix as when multiplied with the original matrix, they rotate the data into the new coordinate system)
# print(pca$x) # the principal component scores for each datapoint
# save biplot
filename <- deparse(substitute(data))
filepath <- paste("~/Desktop/Biplot - ", filename, ".png", sep = "")
png(filepath, width = 800, height = 800) # set output (default w,h = 480)
biplot(pca, scale = 0) # produce plot
dev.off() # reset default output
}
pca.run.to.biplot(df.pca.words.nonsparse)
pca.run.to.biplot(df.pca.words.sparse)
pca.run.to.biplot(df.pca.lemma.nonsparse)
pca.run.to.biplot(df.pca.lemma.sparse)
pca.show.var.explained(df.pca.words.nonsparse)
pca.show.var.explained(df.pca.words.sparse)
pca.show.var.explained(df.pca.lemma.nonsparse)
pca.show.var.explained(df.pca.lemma.sparse)
FMR.pca.lemma.sparse <- PCA(df.pca.lemma.sparse)
head(df.pca.lemma.sparse)
df.pca.lemma.sparse*100
head(df.pca.lemma.sparse*100)
head(df.pca.lemma.sparse)
head(df.pca.lemma.sparse*100)
df.test <- head(df.pca.lemma.sparse*1000)
pca.show.var.explained(df.test)
dim(df.test)
df.test <- df.pca.lemma.sparse*1000
dim(df.test)
df.test <- df.pca.lemma.nonsparse*1000
dim(df.test)
pca.show.var.explained(df.test)
PCA(df.test)
corpus.words.orig <- VCorpus(VectorSource(vec.words))
corpus.lemma.orig <- VCorpus(VectorSource(vec.lemma))
for (i in 1:length(text.names)) meta(corpus.words.orig[[i]])$heading <- text.names[[i]]
for (i in 1:length(text.names)) meta(corpus.lemma.orig[[i]])$heading <- text.names[[i]]
corpus.words <- corpus.words.orig # these will remain as original corpuses
corpus.lemma <- corpus.lemma.orig
length(corpus.words)
inspect(corpus.words)
str(corpus.words)
corpus.words <- tm_map(corpus.words.orig, stripWhitespace)
corpus.lemma <- tm_map(corpus.lemma.orig, stripWhitespace)
corpus.words <- tm_map(corpus.words, content_transformer(tolower))
corpus.lemma <- tm_map(corpus.lemma, content_transformer(tolower))
start <- Sys.time() # duration wrapper
corpus.words <- tm_map(corpus.words, removeWords, stopwords(kind = "en"))
(dur <- Sys.time() - start) # duration wrapper
vec.stopwords.words
corpus.words <- tm_map(corpus.words, removeWords, vec.stopwords.words) # additional words to remove after eye-checking the word-vector (see below)
corpus.lemma <- tm_map(corpus.lemma, removeWords, stopwords(kind = "en"))
corpus.lemma <- tm_map(corpus.lemma, removeWords, vec.stopwords.lemmas) # additional lemmas to remove after eye-checking the lemma-vector (see below)
corpus.words <- tm_map(corpus.words, stemDocument)
corpus.words <- tm_map(corpus.words, removePunctuation, preserve_intra_word_dashes = TRUE)
corpus.lemma <- tm_map(corpus.lemma, removePunctuation, preserve_intra_word_dashes = TRUE)
corpus.words <- tm_map(corpus.words, removeNumbers)
corpus.lemma <- tm_map(corpus.lemma, removeNumbers)
object.size(corpus.words)
object.size(corpus.lemma)
vec.begin <- vector()
for (i in 1:length(corpus.words)) {
vec.begin[i] <- corpus.words[[i]] %>% as.character() %>% substr(1,20) %>% print
}
which(duplicated(vec.begin)) # should be 0 - otherwise shows the element indeces that are duplicate
tdm.words.sparse <- TermDocumentMatrix(corpus.words)
tdm.lemma.sparse <- TermDocumentMatrix(corpus.lemma)
inspect(tdm.words.sparse[1:10,1:4])
inspect(tdm.lemma.sparse[1:10,1:4])
length(tdm.words.sparse$dimnames$Terms) # check length of matrix
length(findFreqTerms(tdm.words.sparse,10)) # find frequent terms
length(findFreqTerms(tdm.words.sparse,100)) # find frequent terms
length(findFreqTerms(tdm.words.sparse,1000)) # find frequent terms
head(findFreqTerms(tdm.words.sparse,10000)) # find frequent terms
a <- tdm.words.sparse %>% as.matrix() %>% as.data.frame()
b <- rownames(a)
c <- apply(a,1,sum)
df.words <- data_frame(word=b,count=c)
df.words %>% arrange(desc(count))
which(b %in% "the")
write_csv(df.words, '~/Google Drive/viz/projects/text analysis/3 medium.com/plots/words.csv')
vec.stopwords.words <- c("the","can","this","also","and","but","for")
vec.stopwords.lemmas <- c("can","also")
fun.sparsity.vis(tdm.words.sparse)
fun.sparsity.vis <- function(matrix) {
# create vector with
v <- numeric(0)
v <- append(v, removeSparseTerms(matrix, 0.01)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.1)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.2)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.3)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.4)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.5)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.6)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.7)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.8)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.9)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.99)$nrow)
df <- data_frame(max.sparsity=c(0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99),
n=v) # data to plot
print(df)
# plot minimum's by returned words > choose visually (maybe the elbow)
ggplot(df,aes(max.sparsity, n, label = n)) +
geom_line() +
geom_label() +
labs(x = "maximum allowed sparsity per term in %", y = "number of retained terms in matrix")
}
fun.sparsity.vis(tdm.words.sparse)
fun.sparsity.vis(tdm.lemma.sparse)
save.image("~/Google Drive/viz/projects/text analysis/3 medium.com/workspaces/16 06 16.RData")
load("~/Google Drive/viz/projects/text analysis/3 medium.com/workspaces/16 06 16.RData")
class(tdm.words.sparse)
fun.sparsity.vis(tdm.words.sparse)
require("tm")
class(tdm.words.sparse)
fun.sparsity.vis(tdm.words.sparse)
fun.sparsity.vis(tdm.lemma.sparse)
df.tdm.words.sparse <- tdm.words.sparse %>% as.matrix() %>% as.data.frame()
nrow(df.tdm.words.sparse)
df.pca.words.sparse <- df.tdm.words.sparse
head(df.pca.words.sparse)
pca.run.to.biplot(df.pca.words.sparse)
FMR.pca.words.sparse <- PCA(df.pca.words.sparse)
library("FactoMineR", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
FMR.pca.words.sparse <- PCA(df.pca.words.sparse)
print(FMR.pca.words.sparse)
FMR.pca.words.sparse$eig
head(df.pca.words.sparse)
head(df.pca.words.sparse[,1:2])
FMR.pca.words.sparse <- PCA(df.pca.words.sparse[,1:2])
head(df.pca.words.sparse[,1:2])
head(df.pca.words.sparse[1:200,1:2])
FMR.pca.words.sparse <- PCA(df.pca.words.sparse[1:200,1:2])
FMR.pca.words.sparse <- PCA(df.pca.words.sparse[1:50,1:2])
head(df.pca.words.sparse %>% arrange(desc(1)))
names(df.pca.words.sparse)
names(arrange(df.pca.words.sparse))
arrange(df.pca.words.sparse)
head(arrange(df.pca.words.sparse))
head(arrange(df.pca.words.sparse,1))
head(arrange(df.pca.words.sparse,"1"))
arrange(df.pca.words.sparse,"1")
arrange(df.pca.words.sparse,df.pca.words.sparse[,1])
head(arrange(df.pca.words.sparse,df.pca.words.sparse[,1]))
head(arrange(df.pca.words.sparse,desc(df.pca.words.sparse[,1])))
FMR.pca.words.sparse <- PCA(arrange(df.pca.words.sparse,desc(df.pca.words.sparse[,1]))[1:50,1:2])
head(df.pca.words.sparse[1:50,1:2])
test <- df.pca.words.sparse[1:50,1:2]
test
head(test)
arrange(df.pca.words.sparse, df.pca.words.sparse[,1])
head(df.pca.words.sparse)
rownames(df.pca.words.sparse)
FMR.pca.words.sparse <- PCA(df.pca.words.sparse[1:50,1:2])
FMR.pca.words.sparse <- PCA(df.pca.words.sparse[1:20,1:2])
FMR.pca.lemma.sparse <- PCA(df.pca.words.sparse[1:20,1:2])
df.pca.words.sparse[1:20,1:2]
FMR.pca.lemma.sparse <- PCA(df.pca.words.sparse[50:70,1:2])
df.pca.words.sparse[50:70,1:2]
FMR.ca.words.sparse <- CA(df.pca.words.sparse[50:70,1:2])
head(df.pca.words.sparse[50:70,1:2])
head(df.pca.words.sparse[50:52,1:2])
head(df.pca.words.sparse[1:20,1:2])
df.pca.words.sparse[1:20,1:2]
df.pca.words.sparse[20:40,1:2]
FMR.ca.words.sparse <- CA(df.pca.words.sparse[20:40,1:2])
FMR.ca.words.sparse <- PCA(df.pca.words.sparse[20:40,1:2])
women_work=read.table("http://factominer.free.fr/classical-methods/datasets/women_work.txt", header=TRUE, row.names=1, sep="\t")
women_work
women_work[,1:3]
t <- women_work[,1:3]
str(t)
str(df.pca.words.sparse)
FMR.ca.words.sparse <- CA(df.pca.words.sparse[20:40,1:2])
save.image("~/Google Drive/viz/projects/text analysis/3 medium.com/workspaces/16 06 20.RData")
load("~/Google Drive/viz/projects/text analysis/2 gutenberg/workspaces/160520.RData")
load("~/Google Drive/viz/projects/text analysis/3 medium.com/workspaces/16 06 20.RData")
df.dtm.lemma.nonsparse <- t(df.tdm.lemma.nonsparse)
ncol(df.dtm.lemma.nonsparse)
View(df.dtm.lemma.nonsparse)
View(df.tdm.lemma.nonsparse)
inspect(tdm.words.sparse[1:10,1:4])
library("FactoMineR", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("tm", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
inspect(tdm.words.sparse[1:10,1:4])
inspect(tdm.lemma.sparse[1:10,1:4])
head(tdm.lemma.nonsparse)
str(tdm.lemma.nonsparse)
str(tdm.lemma.nonsparse)
class(tdm.lemma.nonsparse)
df.tdm.lemma.nonsparse <- tdm.lemma.nonsparse %>% as.matrix() %>% as.data.frame()
head(df.tdm.lemma.nonsparse)
tdm.words.sparse <- TermDocumentMatrix(corpus.words)
tdm.lemma.sparse <- TermDocumentMatrix(corpus.lemma)
tdm.lemma.sparse
inspect(tdm.words.sparse[1:10,1:4])
inspect(tdm.lemma.sparse[1:10,1:4])
tdm.words.nonsparse <- removeSparseTerms(tdm.words.sparse, 0.9)
tdm.lemma.nonsparse <- removeSparseTerms(tdm.lemma.sparse, 0.9)
df.tdm.words.nonsparse <- tdm.words.nonsparse %>% as.matrix() %>% as.data.frame()
df.tdm.lemma.nonsparse <- tdm.lemma.nonsparse %>% as.matrix() %>% as.data.frame()
df.tdm.words.sparse <- tdm.words.sparse %>% as.matrix() %>% as.data.frame()
df.tdm.lemma.sparse <- tdm.lemma.sparse %>% as.matrix() %>% as.data.frame()
df.dtm.lemma.nonsparse <- t(df.tdm.lemma.nonsparse)
View(df.tdm.lemma.nonsparse)
df.pca.words.nonsparse <- df.tdm.words.nonsparse
df.pca.words.sparse <- df.tdm.words.sparse
df.pca.lemma.nonsparse <- df.tdm.lemma.nonsparse
df.pca.lemma.sparse <- df.tdm.lemma.sparse
df.pca.lemma.nonsparse.dtm <- df.dtm.lemma.nonsparse
facto.pca.tdm <- PCA(df.pca.lemma.nonsparse)
barplot(facto.pca.tdms$eig[,1], main = "Eigenvalues",
names.arg = paste("Dim", 1:nrow(facto.pca.tdm$eig), sep = ""))
barplot(facto.pca.tdm$eig[,1], main = "Eigenvalues",
names.arg = paste("Dim", 1:nrow(facto.pca.tdm$eig), sep = ""))
facto.pca.dtm <- PCA(df.pca.lemma.nonsparse.dtm)
barplot(facto.pca.dtm$eig[,1], main = "Eigenvalues",
names.arg = paste("Dim", 1:nrow(facto.pca.dtm$eig), sep = ""))
df.dtm.words.nonsparse <- t(df.tdm.words.nonsparse)
df.dtm.words.sparse <- t(df.tdm.words.sparse)
df.pca.words.nonsparse.dtm <- df.dtm.words.nonsparse
df.pca.words.sparse.dtm <- df.dtm.words.sparse
facto.pca.dtm.lns <- PCA(df.pca.lemma.nonsparse.dtm)
print(facto.pca.dtm.lns)
# Eigenvalues plotting
barplot(facto.pca.dtm.lns$eig[,1], main = "Eigenvalues",
names.arg = paste("Dim", 1:nrow(facto.pca.dtm.lns$eig), sep = ""))
facto.pca.dtm.wns <- PCA(df.pca.words.nonsparse.dtm)
barplot(facto.pca.dtm.wns$eig[,1], main = "Eigenvalues",
names.arg = paste("Dim", 1:nrow(facto.pca.dtm.wns$eig), sep = ""))
facto.pca.dtm.ws <- PCA(df.pca.words.sparse.dtm)
save.image("~/Google Drive/viz/projects/text analysis/3 medium.com/workspaces/16 07 31.RData")
load("~/Google Drive/viz/projects/text analysis/2 gutenberg/workspaces/160620.RData")
head(df.pca.lemma.nonsparse)
View(df.pca.lemma.nonsparse)
getwd()
write_csv(df.pca.lemma.nonsparse ,"~/Downloads")
write_csv(df.pca.lemma.nonsparse ,"~")
write_csv(df.pca.lemma.nonsparse,"~")
write_csv(df.pca.lemma.nonsparse)
write_csv(df.pca.lemma.nonsparse, "~/blub.csv")
rownames(df.pca.lemma.nonsparse)
b <- rownames(df.pca.lemma.nonsparse)
as.data.frame(b)
head(as.data.frame(b),100)
install.packages("ggplot2movies")
library("ggplot2movies", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
View(ggplot2movies)
load(ggplot2movies)
head(movies)
length(movies)
View(movies)
str(movies)
movies$budget
is.na(movies$budget)
sum(is.na(movies$budget))
nrow(movies$budget)
dim(movies$budget)
nrow(movies)
nrow(movies) - sum(is.na(movies$budget))
(nrow(movies) - sum(is.na(movies$budget)))/ nrow(movies)
str(movies)
max(movies$year)
min(movies$year)
capacity <- read.delim("clipboard", header = T)
capacity <- read.delim("clipboard", header = T)
getwd()
setwd('./desktop')
getwd()
setwd('./Google Drive/viz/projects/map')
setwd('./Google\ Drive/viz/projects/map')
setwd('./Google Drive')
?setwd
setwd('/Users/lars/Google Drive/viz/projects/map')
getwd()
loc <- read.xlsx2('olympics.xlsx',sheetName = 'locations')
setwd('/Users/lars/Google Drive/viz/projects/map/olympics')
getwd()
loc <- read.xlsx2('olympics.xlsx',sheetName = 'locations')
View(loc)
cap <- select(loc, capacity)
cap
cap <- filter(cap, cap > 0)
is.na(cap)
cap[209]
cap[209,]
str(cap)
as.numeric(as.character(cap))
cap <- as.numeric(as.character(cap))
cap
str(cap)
cap <- select(loc, capacity)
str(cap)
cap <- as.numeric(as.character(cap$capacity))
cap
summary(cap)
hist(cap)
densityplot(cap)
densityplot(cap)
boxplot(cap)
stripplot(cap)
stripplot(cap)
sd(cap)
?sd
sd(cap, na.rm = true)
sd(cap, na.rm = T)
var(cap, na.rm = T)
