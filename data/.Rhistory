inspect(tdm.words.sparse[1:10,1:20])
str(tdm.test)
str(tdm.words.sparse)
str(tdm.test)
inspect(tdm.words.sparse[1:10,1:20])
inspect(tdm.test[1:10,1:20])
df.tdm.test <- tdm.test %>% as.matrix() %>% as.data.frame()
df.pca.test <- df.tdm.test
pca.run.to.biplot(df.tdm.test)
blub <- PCA(df.tdm.test)
pca.show.var.explained(df.tdm.test)
tdm.words.sparse <- TermDocumentMatrix(corpus.words, control = list(weighting = weightTfIdf))
tdm.lemma.sparse <- TermDocumentMatrix(corpus.lemma, control = list(weighting = weightTfIdf))
inspect(tdm.words.sparse[1:10,1:4])
inspect(tdm.lemma.sparse[1:10,1:4])
length(tdm.words.sparse$dimnames$Terms) # check length of matrix
length(findFreqTerms(tdm.words.sparse,10)) # find frequent terms
length(findFreqTerms(tdm.words.sparse,100)) # find frequent terms
length(findFreqTerms(tdm.words.sparse,1000)) # find frequent terms
head(findFreqTerms(tdm.words.sparse,10000)) # find frequent terms
a <- tdm.words.sparse %>% as.matrix() %>% as.data.frame()
b <- rownames(a)
c <- apply(a,1,sum)
df.words <- data_frame(word=b,count=c)
which(b %in% "the")
(df.words <- data_frame(word=b,count=c))
(df.words %>% arrange(desc(word)))
(df.words %>% arrange(desc(count)))
(df.words %>% arrange(count))
a <- tdm.lemma.sparse %>% as.matrix() %>% as.data.frame()
b <- rownames(a)
c <- apply(a,1,sum)
df.lemmas <- data_frame(word=b,count=c)
df.lemmas %>% arrange(desc(count))
fun.sparsity.vis <- function(matrix) {
# create vector with
v <- numeric(0)
v <- append(v, removeSparseTerms(matrix, 0.01)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.1)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.2)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.3)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.4)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.5)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.6)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.7)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.8)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.9)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.99)$nrow)
df <- data_frame(max.sparsity=c(0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99),
n=v) # data to plot
print(df)
# plot minimum's by returned words > choose visually (maybe the elbow)
ggplot(df,aes(max.sparsity, n, label = n)) +
geom_line() +
geom_label() +
labs(x = "maximum allowed sparsity per term in %", y = "number of retained terms in matrix")
}
fun.sparsity.vis(tdm.words.sparse)
fun.sparsity.vis(tdm.lemma.sparse)
tdm.words.nonsparse <- removeSparseTerms(tdm.words.sparse, 0.9)
tdm.lemma.nonsparse <- removeSparseTerms(tdm.lemma.sparse, 0.9)
fun.sparsity.vis(tdm.words.nonsparse)
fun.sparsity.vis(tdm.lemma.nonsparse)
df.tdm.words.nonsparse <- tdm.words.nonsparse %>% as.matrix() %>% as.data.frame()
df.tdm.lemma.nonsparse <- tdm.lemma.nonsparse %>% as.matrix() %>% as.data.frame()
df.tdm.words.sparse <- tdm.words.sparse %>% as.matrix() %>% as.data.frame()
df.tdm.lemma.sparse <- tdm.lemma.sparse %>% as.matrix() %>% as.data.frame()
nrow(df.tdm.lemma.nonsparse)
nrow(df.tdm.lemma.sparse)
nrow(df.tdm.words.nonsparse)
nrow(df.tdm.words.sparse)
head(df.tdm.words.nonsparse)
head(df.tdm.words.sparse)
head(df.tdm.lemma.nonsparse)
head(df.tdm.lemma.sparse)
fun.check.word.frequency <- function(data, NoOfWordsToShow = 500) {
f.sum <- rowSums(data)
f.stdev <- apply(data,1,sd)
f.words <- names(f.sum)
df.wordfreq <- data_frame(word = f.words, freq = f.sum, st.dev = f.stdev) # create df
df.wordfreq <- arrange(df.wordfreq,desc(freq)) # sort by word frequency
df.wordfreq <- mutate(df.wordfreq, division = st.dev/freq*100) # add variable that shows st.dev in relation to frequency. Remove only values were this measure is high (we want to keep words with a high standard deviation in relation to their frequency as should retain a reasonable amount of discriminatory value for the text clustering)
print(df.wordfreq, n = 20) # print the first 20 words
data.name <- deparse(substitute(data)) # get data object name
# show the top 100 frequent words
print(ggplot(df.wordfreq[1:NoOfWordsToShow,], aes(c(1:NoOfWordsToShow), freq)) +
geom_point() +
labs(title = paste("word frequency of", data.name, "\n for the", NoOfWordsToShow, "top occuring words - before removal"),
x = paste("top", NoOfWordsToShow, "words"),
y = "word frequency"))
return(df.wordfreq)
}
fun.remove.very.frequent.terms <- function(tdmatrix, maxNumOfWords = 10000) {
# create dataframe of words to keep
df.wordfreq <- df.wordfreq %>% dplyr::filter(freq < maxNumOfWords | (freq > maxNumOfWords & division > 4 )) # remove all words used more often than 'maxNumOfWords' times OR has a high standard dev.
df.wordfreq <- df.wordfreq %>% dplyr::filter(word != "and") # remove "and"
print(df.wordfreq, n = 20) # print frequent terms df with removed terms
data.name <- deparse(substitute(tdmatrix)) # get data name as character
# show plot
print(ggplot(df.wordfreq[1:100,], aes(c(1:100), freq)) +
geom_point() +
labs(title = paste("word frequency of", data.name, "\n for the 100 top occuring words - after removal"),
x = "top 100 words",
y = "word frequency"))
# create matrix with words to keep
vec.keep <- as.vector(unlist(df.wordfreq[,1]))
vec.keep <- sort(vec.keep)
r <- nrow(tdmatrix)
print(paste("rows of original tdm: ", r))
tdmatrix <- tdmatrix[vec.keep,]
print(paste("rows of new tdm: ", nrow(tdmatrix)))
print(paste("number of terms removed: ", r - nrow(tdmatrix)))
return(tdmatrix)
}
df.wordfreq <- fun.check.word.frequency(df.tdm.words.nonsparse) # look at the sorted word frequency
df.wordfreq <- fun.check.word.frequency(df.tdm.words.sparse) # look at the sorted word frequency
df.wordfreq <- fun.check.word.frequency(df.tdm.lemma.nonsparse) # look at the sorted word frequency
df.wordfreq <- fun.check.word.frequency(df.tdm.lemma.sparse) # look at the sorted word frequency
df.pca.words.nonsparse <- df.tdm.words.nonsparse
df.pca.words.sparse <- df.tdm.words.sparse
df.pca.lemma.nonsparse <- df.tdm.lemma.nonsparse
df.pca.lemma.sparse <- df.tdm.lemma.sparse
colnames(df.pca.words.nonsparse) <- text.names
colnames(df.pca.words.sparse) <- text.names
colnames(df.pca.lemma.nonsparse) <- text.names
colnames(df.pca.lemma.sparse) <- text.names
head(df.pca.words.nonsparse)
summary(df.pca.words.nonsparse)
View(df.pca.lemma.sparse)
pca.run.to.biplot <- function(data){
# run pca (w. standardsed data - ie. center and scale)
pca <- prcomp(data, scale. = T)
# diagnostics
print(pca$center) # the means used for centering
print(pca$scale) # the standard dev's used for scaling
print(pca$rotation) # the principal components (called the rotation matrix as when multiplied with the original matrix, they rotate the data into the new coordinate system)
# print(pca$x) # the principal component scores for each datapoint
# save biplot
filename <- deparse(substitute(data))
filepath <- paste("~/Desktop/Biplot - ", filename, ".png", sep = "")
png(filepath, width = 800, height = 800) # set output (default w,h = 480)
biplot(pca, scale = 0) # produce plot
dev.off() # reset default output
}
pca.run.to.biplot(df.pca.words.nonsparse)
pca.run.to.biplot(df.pca.words.sparse)
pca.run.to.biplot(df.pca.lemma.nonsparse)
pca.run.to.biplot(df.pca.lemma.sparse)
pca.show.var.explained(df.pca.words.nonsparse)
pca.show.var.explained(df.pca.words.sparse)
pca.show.var.explained(df.pca.lemma.nonsparse)
pca.show.var.explained(df.pca.lemma.sparse)
FMR.pca.lemma.sparse <- PCA(df.pca.lemma.sparse)
head(df.pca.lemma.sparse)
df.pca.lemma.sparse*100
head(df.pca.lemma.sparse*100)
head(df.pca.lemma.sparse)
head(df.pca.lemma.sparse*100)
df.test <- head(df.pca.lemma.sparse*1000)
pca.show.var.explained(df.test)
dim(df.test)
df.test <- df.pca.lemma.sparse*1000
dim(df.test)
df.test <- df.pca.lemma.nonsparse*1000
dim(df.test)
pca.show.var.explained(df.test)
PCA(df.test)
corpus.words.orig <- VCorpus(VectorSource(vec.words))
corpus.lemma.orig <- VCorpus(VectorSource(vec.lemma))
for (i in 1:length(text.names)) meta(corpus.words.orig[[i]])$heading <- text.names[[i]]
for (i in 1:length(text.names)) meta(corpus.lemma.orig[[i]])$heading <- text.names[[i]]
corpus.words <- corpus.words.orig # these will remain as original corpuses
corpus.lemma <- corpus.lemma.orig
length(corpus.words)
inspect(corpus.words)
str(corpus.words)
corpus.words <- tm_map(corpus.words.orig, stripWhitespace)
corpus.lemma <- tm_map(corpus.lemma.orig, stripWhitespace)
corpus.words <- tm_map(corpus.words, content_transformer(tolower))
corpus.lemma <- tm_map(corpus.lemma, content_transformer(tolower))
start <- Sys.time() # duration wrapper
corpus.words <- tm_map(corpus.words, removeWords, stopwords(kind = "en"))
(dur <- Sys.time() - start) # duration wrapper
vec.stopwords.words
corpus.words <- tm_map(corpus.words, removeWords, vec.stopwords.words) # additional words to remove after eye-checking the word-vector (see below)
corpus.lemma <- tm_map(corpus.lemma, removeWords, stopwords(kind = "en"))
corpus.lemma <- tm_map(corpus.lemma, removeWords, vec.stopwords.lemmas) # additional lemmas to remove after eye-checking the lemma-vector (see below)
corpus.words <- tm_map(corpus.words, stemDocument)
corpus.words <- tm_map(corpus.words, removePunctuation, preserve_intra_word_dashes = TRUE)
corpus.lemma <- tm_map(corpus.lemma, removePunctuation, preserve_intra_word_dashes = TRUE)
corpus.words <- tm_map(corpus.words, removeNumbers)
corpus.lemma <- tm_map(corpus.lemma, removeNumbers)
object.size(corpus.words)
object.size(corpus.lemma)
vec.begin <- vector()
for (i in 1:length(corpus.words)) {
vec.begin[i] <- corpus.words[[i]] %>% as.character() %>% substr(1,20) %>% print
}
which(duplicated(vec.begin)) # should be 0 - otherwise shows the element indeces that are duplicate
tdm.words.sparse <- TermDocumentMatrix(corpus.words)
tdm.lemma.sparse <- TermDocumentMatrix(corpus.lemma)
inspect(tdm.words.sparse[1:10,1:4])
inspect(tdm.lemma.sparse[1:10,1:4])
length(tdm.words.sparse$dimnames$Terms) # check length of matrix
length(findFreqTerms(tdm.words.sparse,10)) # find frequent terms
length(findFreqTerms(tdm.words.sparse,100)) # find frequent terms
length(findFreqTerms(tdm.words.sparse,1000)) # find frequent terms
head(findFreqTerms(tdm.words.sparse,10000)) # find frequent terms
a <- tdm.words.sparse %>% as.matrix() %>% as.data.frame()
b <- rownames(a)
c <- apply(a,1,sum)
df.words <- data_frame(word=b,count=c)
df.words %>% arrange(desc(count))
which(b %in% "the")
write_csv(df.words, '~/Google Drive/viz/projects/text analysis/3 medium.com/plots/words.csv')
vec.stopwords.words <- c("the","can","this","also","and","but","for")
vec.stopwords.lemmas <- c("can","also")
fun.sparsity.vis(tdm.words.sparse)
fun.sparsity.vis <- function(matrix) {
# create vector with
v <- numeric(0)
v <- append(v, removeSparseTerms(matrix, 0.01)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.1)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.2)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.3)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.4)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.5)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.6)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.7)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.8)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.9)$nrow)
v <- append(v, removeSparseTerms(matrix, 0.99)$nrow)
df <- data_frame(max.sparsity=c(0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99),
n=v) # data to plot
print(df)
# plot minimum's by returned words > choose visually (maybe the elbow)
ggplot(df,aes(max.sparsity, n, label = n)) +
geom_line() +
geom_label() +
labs(x = "maximum allowed sparsity per term in %", y = "number of retained terms in matrix")
}
fun.sparsity.vis(tdm.words.sparse)
fun.sparsity.vis(tdm.lemma.sparse)
save.image("~/Google Drive/viz/projects/text analysis/3 medium.com/workspaces/16 06 16.RData")
load("~/Google Drive/viz/projects/text analysis/3 medium.com/workspaces/16 06 16.RData")
class(tdm.words.sparse)
fun.sparsity.vis(tdm.words.sparse)
require("tm")
class(tdm.words.sparse)
fun.sparsity.vis(tdm.words.sparse)
fun.sparsity.vis(tdm.lemma.sparse)
df.tdm.words.sparse <- tdm.words.sparse %>% as.matrix() %>% as.data.frame()
nrow(df.tdm.words.sparse)
df.pca.words.sparse <- df.tdm.words.sparse
head(df.pca.words.sparse)
pca.run.to.biplot(df.pca.words.sparse)
FMR.pca.words.sparse <- PCA(df.pca.words.sparse)
library("FactoMineR", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
FMR.pca.words.sparse <- PCA(df.pca.words.sparse)
print(FMR.pca.words.sparse)
FMR.pca.words.sparse$eig
head(df.pca.words.sparse)
head(df.pca.words.sparse[,1:2])
FMR.pca.words.sparse <- PCA(df.pca.words.sparse[,1:2])
head(df.pca.words.sparse[,1:2])
head(df.pca.words.sparse[1:200,1:2])
FMR.pca.words.sparse <- PCA(df.pca.words.sparse[1:200,1:2])
FMR.pca.words.sparse <- PCA(df.pca.words.sparse[1:50,1:2])
head(df.pca.words.sparse %>% arrange(desc(1)))
names(df.pca.words.sparse)
names(arrange(df.pca.words.sparse))
arrange(df.pca.words.sparse)
head(arrange(df.pca.words.sparse))
head(arrange(df.pca.words.sparse,1))
head(arrange(df.pca.words.sparse,"1"))
arrange(df.pca.words.sparse,"1")
arrange(df.pca.words.sparse,df.pca.words.sparse[,1])
head(arrange(df.pca.words.sparse,df.pca.words.sparse[,1]))
head(arrange(df.pca.words.sparse,desc(df.pca.words.sparse[,1])))
FMR.pca.words.sparse <- PCA(arrange(df.pca.words.sparse,desc(df.pca.words.sparse[,1]))[1:50,1:2])
head(df.pca.words.sparse[1:50,1:2])
test <- df.pca.words.sparse[1:50,1:2]
test
head(test)
arrange(df.pca.words.sparse, df.pca.words.sparse[,1])
head(df.pca.words.sparse)
rownames(df.pca.words.sparse)
FMR.pca.words.sparse <- PCA(df.pca.words.sparse[1:50,1:2])
FMR.pca.words.sparse <- PCA(df.pca.words.sparse[1:20,1:2])
FMR.pca.lemma.sparse <- PCA(df.pca.words.sparse[1:20,1:2])
df.pca.words.sparse[1:20,1:2]
FMR.pca.lemma.sparse <- PCA(df.pca.words.sparse[50:70,1:2])
df.pca.words.sparse[50:70,1:2]
FMR.ca.words.sparse <- CA(df.pca.words.sparse[50:70,1:2])
head(df.pca.words.sparse[50:70,1:2])
head(df.pca.words.sparse[50:52,1:2])
head(df.pca.words.sparse[1:20,1:2])
df.pca.words.sparse[1:20,1:2]
df.pca.words.sparse[20:40,1:2]
FMR.ca.words.sparse <- CA(df.pca.words.sparse[20:40,1:2])
FMR.ca.words.sparse <- PCA(df.pca.words.sparse[20:40,1:2])
women_work=read.table("http://factominer.free.fr/classical-methods/datasets/women_work.txt", header=TRUE, row.names=1, sep="\t")
women_work
women_work[,1:3]
t <- women_work[,1:3]
str(t)
str(df.pca.words.sparse)
FMR.ca.words.sparse <- CA(df.pca.words.sparse[20:40,1:2])
save.image("~/Google Drive/viz/projects/text analysis/3 medium.com/workspaces/16 06 20.RData")
load("~/Google Drive/viz/projects/text analysis/2 gutenberg/workspaces/160520.RData")
load("~/Google Drive/viz/projects/text analysis/3 medium.com/workspaces/16 06 20.RData")
df.dtm.lemma.nonsparse <- t(df.tdm.lemma.nonsparse)
ncol(df.dtm.lemma.nonsparse)
View(df.dtm.lemma.nonsparse)
View(df.tdm.lemma.nonsparse)
inspect(tdm.words.sparse[1:10,1:4])
library("FactoMineR", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("tm", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
inspect(tdm.words.sparse[1:10,1:4])
inspect(tdm.lemma.sparse[1:10,1:4])
head(tdm.lemma.nonsparse)
str(tdm.lemma.nonsparse)
str(tdm.lemma.nonsparse)
class(tdm.lemma.nonsparse)
df.tdm.lemma.nonsparse <- tdm.lemma.nonsparse %>% as.matrix() %>% as.data.frame()
head(df.tdm.lemma.nonsparse)
tdm.words.sparse <- TermDocumentMatrix(corpus.words)
tdm.lemma.sparse <- TermDocumentMatrix(corpus.lemma)
tdm.lemma.sparse
inspect(tdm.words.sparse[1:10,1:4])
inspect(tdm.lemma.sparse[1:10,1:4])
tdm.words.nonsparse <- removeSparseTerms(tdm.words.sparse, 0.9)
tdm.lemma.nonsparse <- removeSparseTerms(tdm.lemma.sparse, 0.9)
df.tdm.words.nonsparse <- tdm.words.nonsparse %>% as.matrix() %>% as.data.frame()
df.tdm.lemma.nonsparse <- tdm.lemma.nonsparse %>% as.matrix() %>% as.data.frame()
df.tdm.words.sparse <- tdm.words.sparse %>% as.matrix() %>% as.data.frame()
df.tdm.lemma.sparse <- tdm.lemma.sparse %>% as.matrix() %>% as.data.frame()
df.dtm.lemma.nonsparse <- t(df.tdm.lemma.nonsparse)
View(df.tdm.lemma.nonsparse)
df.pca.words.nonsparse <- df.tdm.words.nonsparse
df.pca.words.sparse <- df.tdm.words.sparse
df.pca.lemma.nonsparse <- df.tdm.lemma.nonsparse
df.pca.lemma.sparse <- df.tdm.lemma.sparse
df.pca.lemma.nonsparse.dtm <- df.dtm.lemma.nonsparse
facto.pca.tdm <- PCA(df.pca.lemma.nonsparse)
barplot(facto.pca.tdms$eig[,1], main = "Eigenvalues",
names.arg = paste("Dim", 1:nrow(facto.pca.tdm$eig), sep = ""))
barplot(facto.pca.tdm$eig[,1], main = "Eigenvalues",
names.arg = paste("Dim", 1:nrow(facto.pca.tdm$eig), sep = ""))
facto.pca.dtm <- PCA(df.pca.lemma.nonsparse.dtm)
barplot(facto.pca.dtm$eig[,1], main = "Eigenvalues",
names.arg = paste("Dim", 1:nrow(facto.pca.dtm$eig), sep = ""))
df.dtm.words.nonsparse <- t(df.tdm.words.nonsparse)
df.dtm.words.sparse <- t(df.tdm.words.sparse)
df.pca.words.nonsparse.dtm <- df.dtm.words.nonsparse
df.pca.words.sparse.dtm <- df.dtm.words.sparse
facto.pca.dtm.lns <- PCA(df.pca.lemma.nonsparse.dtm)
print(facto.pca.dtm.lns)
# Eigenvalues plotting
barplot(facto.pca.dtm.lns$eig[,1], main = "Eigenvalues",
names.arg = paste("Dim", 1:nrow(facto.pca.dtm.lns$eig), sep = ""))
facto.pca.dtm.wns <- PCA(df.pca.words.nonsparse.dtm)
barplot(facto.pca.dtm.wns$eig[,1], main = "Eigenvalues",
names.arg = paste("Dim", 1:nrow(facto.pca.dtm.wns$eig), sep = ""))
facto.pca.dtm.ws <- PCA(df.pca.words.sparse.dtm)
save.image("~/Google Drive/viz/projects/text analysis/3 medium.com/workspaces/16 07 31.RData")
load("~/Google Drive/viz/projects/text analysis/2 gutenberg/workspaces/160620.RData")
head(df.pca.lemma.nonsparse)
View(df.pca.lemma.nonsparse)
getwd()
write_csv(df.pca.lemma.nonsparse ,"~/Downloads")
write_csv(df.pca.lemma.nonsparse ,"~")
write_csv(df.pca.lemma.nonsparse,"~")
write_csv(df.pca.lemma.nonsparse)
write_csv(df.pca.lemma.nonsparse, "~/blub.csv")
rownames(df.pca.lemma.nonsparse)
b <- rownames(df.pca.lemma.nonsparse)
as.data.frame(b)
head(as.data.frame(b),100)
install.packages("ggplot2movies")
library("ggplot2movies", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
View(ggplot2movies)
load(ggplot2movies)
head(movies)
length(movies)
View(movies)
str(movies)
movies$budget
is.na(movies$budget)
sum(is.na(movies$budget))
nrow(movies$budget)
dim(movies$budget)
nrow(movies)
nrow(movies) - sum(is.na(movies$budget))
(nrow(movies) - sum(is.na(movies$budget)))/ nrow(movies)
str(movies)
max(movies$year)
min(movies$year)
getwd()
setwd('/Users/lars/Google Drive/viz/projects/map/olympics')
getwd()
read_tsv(nations.tsv)
read_tsv('nations.tsv')
setwd('/Users/lars/Google Drive/viz/projects/map/olympics/data')
getwd()
read_tsv('nations.tsv')
read_txt('nations.tsv')
read.xlsx2('nations.xlsx')
read.xlsx2('nations.xlsx',1)
read.xlsx2('nations.xlsx',1)
d <- read.xlsx2('nations.xlsx',1)
View(d)
d <- read.xlsx2('nations.xlsx',1)
View(d)
d0 <- d %>% filter(event_id = 0)
d0 <- d %>% filter(event_id == 0)
d0 <- d %>% filter('event_id' == 0)
View d0
filter(d, event_id == 0)
d <- tbl_df(d)
filter(d, event_id == 0)
summary(d)
filter(d, place == 'Sochi')
str(d)
d <- read_csv2('nations.csv')
View(d)
d <- read_csv('nations.csv')
View(d)
str(d)
filter(d, event_id == 0)
filter(d, 'event_id' == 0)
filter(d, event_id > 0)
str(d)
d <- read_csv('nations.csv')
View(d)
str(d)
filter(d, event_id > 0)
d0 <- filter(d, event_id > 0)
d0
summary(d)
d0 <- dplyr::filter(d, event_id > 0)
d0
detach("package:dplyr", unload=TRUE)
library("dplyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
d0 <- filter(d, event_id > 0)
d0
d0<- filter(d, event_id >0)
d1<- filter(d, event_id >1)
d2<- filter(d, event_id >2)
d3<- filter(d, event_id >3)
d4<- filter(d, event_id >4)
d5<- filter(d, event_id >5)
d6<- filter(d, event_id >6)
d7<- filter(d, event_id >7)
d8<- filter(d, event_id >8)
d9<- filter(d, event_id >9)
d10<- filter(d, event_id >10)
d11<- filter(d, event_id >11)
d12<- filter(d, event_id >12)
d13<- filter(d, event_id >13)
d14<- filter(d, event_id >14)
d15<- filter(d, event_id >15)
d16<- filter(d, event_id >16)
d17<- filter(d, event_id >17)
d18<- filter(d, event_id >18)
d19<- filter(d, event_id >19)
d20<- filter(d, event_id >20)
d21<- filter(d, event_id >21)
d22<- filter(d, event_id >22)
d23<- filter(d, event_id >23)
hist.default(d0)
hist.default(d0$medals)
densityplot(d0$medals)
densityplot(d0$medals)
densityplot(d1$medals)
densityplot(d2$medals)
densityplot(d3$medals)
densityplot(d4$medals)
densityplot(d5$medals)
densityplot(d6$medals)
densityplot(d7$medals)
densityplot(d8$medals)
densityplot(d9$medals)
densityplot(d10$medals)
densityplot(d11$medals)
densityplot(d12$medals)
densityplot(d13$medals)
densityplot(d14$medals)
densityplot(d15$medals)
densityplot(d16$medals)
densityplot(d17$medals)
densityplot(d18$medals)
densityplot(d19$medals)
densityplot(d20$medals)
densityplot(d21$medals)
densityplot(d22$medals)
densityplot(d23$medals)
densityplot(d22$medals)
densityplot(d21$medals)
densityplot(d16$medals)
densityplot(d17$medals)
densityplot(d18$medals)
densityplot(d19$medals)
densityplot(d20$medals)
densityplot(d21$medals)
densityplot(d22$medals)
dg <- d %>% group_by(event_id)
View(dg)
dg <- d %>% group_by(event_id) %>% summary()
d %>% group_by(event_id) %>% summary()
d %>% dplyr::group_by(event_id) %>% summary()
dplyr::group_by(d, event_id)
